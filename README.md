Analysis to perform:

1. Speed test - float - Cosine Similarity - FLAT
2. Speed test - float - Cosine Similarity - IVF_FLAT

3. Speed test - binary - Hamming - BIN_FLAT
4. Speed test - binary - Hamming - BIN_IVF_FLAT

5. Dimentionality reduction - umap - float
6. Dimentionality reduction - umap - binary

7. Dimentionality reduction - pca - float
8. Dimentionality reduction - pca - binary

9. Dimentionality reduction - mrl - float
10. Dimentionality reduction - mrl - binary

11. Tokenization limit of model

Number of papers with token count > 512: 15548
Number of papers with token count <= 512: 2739378
Percentage of papers with token count > 512: 0.56%
Percentage of papers with token count <= 512: 99.44%
Average token count: 207.62
Median token count: 197.00
Standard deviation of token counts: 97.62
Maximum token count: 1595
Minimum token count: 2
25th percentile of token counts: 136.00
75th percentile of token counts: 268.00
Interquartile range (IQR) of token counts: 132.00
Skewness of token counts: 0.70
Kurtosis of token counts: 0.93